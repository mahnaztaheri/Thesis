{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scispacy==0.2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.5/en_ner_bc5cdr_md-0.2.5.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import scispacy\n",
    "\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2.5\n"
     ]
    }
   ],
   "source": [
    "print(scispacy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the spacy models for disease NER\n",
    "nlp = spacy.load(\"en_ner_bc5cdr_md\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ncbi_txt(file_path):\n",
    "    texts = {}\n",
    "    with open(file_path, \"r\", encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            if line.strip() == \"\":\n",
    "                continue\n",
    "            if \"|t|\" in line:\n",
    "                pmid, title = line.strip().split(\"|t|\")\n",
    "                texts[pmid] = {\"title\": title, \"abstract\": \"\", \"annotations\": []}\n",
    "            elif \"|a|\" in line:\n",
    "                pmid, abstract = line.strip().split(\"|a|\")\n",
    "                if pmid in texts:\n",
    "                    texts[pmid][\"abstract\"] = abstract\n",
    "                else:\n",
    "                    \n",
    "                    texts[pmid] = {\"title\": \"\", \"abstract\": abstract, \"annotations\": []}\n",
    "            else:\n",
    "                parts = line.strip().split(\"\\t\")\n",
    "                if len(parts) >= 5:\n",
    "                    pmid, start, end, mention, label = parts[:5]\n",
    "                    if pmid in texts:\n",
    "                        texts[pmid][\"annotations\"].append({\n",
    "                            \"start\": int(start),\n",
    "                            \"end\": int(end),\n",
    "                            \"mention\": mention,\n",
    "                            \"label\": label\n",
    "                        })\n",
    "    return texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(texts):\n",
    "    predictions = {}\n",
    "    for pmid, entry in texts.items():\n",
    "        doc = nlp(entry[\"title\"] + \" \" + entry[\"abstract\"])\n",
    "        entities = [{\"start\": ent.start_char, \"end\": ent.end_char, \"mention\": ent.text, \"label\": ent.label_}\n",
    "                    for ent in doc.ents if ent.label_ == \"DISEASE\"]\n",
    "        predictions[pmid] = entities\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = load_ncbi_txt(\"D:/scispacy/NCBItestset_corpus/NCBItestset_corpus.txt\")\n",
    "predictions = get_predictions(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions have been saved to predictions.tsv\n"
     ]
    }
   ],
   "source": [
    "output_file = \"predictions.tsv\"\n",
    "\n",
    "with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file, delimiter='\\t')  \n",
    "    \n",
    "    writer.writerow([\"doc_id\", \"start\", \"end\", \"mention\", \"label\"])\n",
    "    \n",
    "    for doc_id, annotations in predictions.items():\n",
    "        for annotation in annotations:\n",
    "            writer.writerow([doc_id, annotation['start'], annotation['end'], annotation['mention'], annotation['label']])\n",
    "\n",
    "print(f\"Predictions have been saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.read_csv(\"D:/scispacy/predictions.tsv\", sep=\"\\t\")\n",
    "gold_df = pd.read_csv(\"D:/OGER/OGER/data/ncbi_annotations/gold_annotations.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_match(pred, gold):\n",
    "    return (\n",
    "        pred['doc_id'] == gold['doc_id'] and\n",
    "        pred['start'] == gold['start'] and\n",
    "        pred['end'] == gold['end'] \n",
    "    )\n",
    "\n",
    "def partial_match(pred, gold):\n",
    "    return (\n",
    "        pred['doc_id'] == gold['doc_id'] and\n",
    "        not (pred['end'] <= gold['start'] or pred['start'] >= gold['end']) \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(pred_df, gold_df, match_func):\n",
    "    tp = 0\n",
    "    matched_gold = set()\n",
    "\n",
    "    for _, pred_row in pred_df.iterrows():\n",
    "        match_found = False\n",
    "        for idx, gold_row in gold_df.iterrows():\n",
    "            if idx in matched_gold:\n",
    "                continue\n",
    "            if match_func(pred_row, gold_row):\n",
    "                tp += 1\n",
    "                matched_gold.add(idx)\n",
    "                match_found = True\n",
    "                break\n",
    "\n",
    "    fp = len(pred_df) - tp\n",
    "    fn = len(gold_df) - tp\n",
    "\n",
    "    precision = tp / (tp + fp) if tp + fp else 0.0\n",
    "    recall = tp / (tp + fn) if tp + fn else 0.0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if precision + recall else 0.0\n",
    "\n",
    "    return precision, recall, f1, fp, fn, tp \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match: P=0.651967, R=0.569792, F1=0.608116, fp=292.000000, fn=413.000000, tp=547.000000\n",
      "Partial Match: P=0.818832, R=0.715625, F1=0.763758, fp=152.000000, fn=273.000000, tp=687.000000\n"
     ]
    }
   ],
   "source": [
    "exact_precision, exact_recall, exact_f1, exact_fp, exact_fn, exact_tp = evaluate(pred_df, gold_df, exact_match)\n",
    "partial_precision, partial_recall, partial_f1, partial_fp, partial_fn, partial_tp = evaluate(pred_df, gold_df, partial_match)\n",
    "\n",
    "print(f\"Exact Match: P={exact_precision:.6f}, R={exact_recall:.6f}, F1={exact_f1:.6f}, fp={exact_fp:.6f}, fn={exact_fn:.6f}, tp={exact_tp:.6f}\")\n",
    "print(f\"Partial Match: P={partial_precision:.6f}, R={partial_recall:.6f}, F1={partial_f1:.6f}, fp={partial_fp:.6f}, fn={partial_fn:.6f}, tp={partial_tp:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scispacy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
